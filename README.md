<!-- # rAVA â€” Arquitetura Neuro-SimbÃ³lica Multimodal

Aerty Pinto dos Santos  

| AVAILABLE DOWNLOADS |
| :------------------: |
| [APRESENTAÃ‡ÃƒO](#apresentaÃ§Ã£o) |
| [VIDEOS](#vÃ­deos) |

---

## Index
- [DescriÃ§Ã£o](#descriÃ§Ã£o)
- [rAVA](#rava)
- [Arquitetura Neuro-SimbÃ³lica Multimodal](#arquitetura-neuro-simbÃ³lica-multimodal)
- [Requisitos do Sistema](#requisitos-do-sistema)
- [InstruÃ§Ãµes para Replicar](#instruÃ§Ãµes-para-replicar)
- [Crie um ambiente com o Miniconda e ative-o](#crie-um-ambiente-com-o-miniconda-e-ative-o)
- [Testes Iniciais](#testes-iniciais)
- [Resultados e DiscussÃ£o](#resultados-e-discussÃ£o)
- [Casos de Uso](#casos-de-uso)
- [ConclusÃ£o](#conclusÃ£o)
- [VÃ­deos](#vÃ­deos)
- [ReferÃªncias](#referÃªncias)

---

## DescriÃ§Ã£o
O **rAVA ** evolui para uma **arquitetura neuro-simbÃ³lica multimodal**, integrando **aprendizado neural** e **razÃ£o simbÃ³lica** em um sistema cognitivo unificado.  
O projeto tem como objetivo ampliar as capacidades de leitura e compreensÃ£o cognitiva do rAVA original â€” inicialmente textual â€” para um modelo capaz de **interpretar voz, imagem e texto** de forma integrada e explicÃ¡vel.  

A proposta posiciona o rAVA como um **cÃ©rebro multimodal**, capaz de **raciocinar simbolicamente, aprender com dados e justificar suas inferÃªncias**, promovendo transparÃªncia e interpretabilidade em tarefas complexas como anÃ¡lise de decisÃµes judiciais e processos educacionais.

---

## rAVA
O rAVA foi concebido a partir da necessidade de desenvolver um **sistema cognitivo interpretÃ¡vel, modular e adaptÃ¡vel**, que pudesse combinar inferÃªncia simbÃ³lica e aprendizado profundo de modo coeso.  

![Arquitetura do rAVA](ravaup.png)

---

## Arquitetura Neuro-SimbÃ³lica Multimodal

O **rAVA** Ã© estruturado em **quatro mÃ³dulos cognitivos principais**, interligados por um nÃºcleo de controle responsÃ¡vel pela coerÃªncia e integraÃ§Ã£o do raciocÃ­nio global do sistema.

- **Arithmetic Reasoning:**  
  ResponsÃ¡vel pela **manipulaÃ§Ã£o e inferÃªncia quantitativa**, permitindo que o sistema realize **operaÃ§Ãµes matemÃ¡ticas, estimativas e deduÃ§Ãµes numÃ©ricas**.  
  Esse mÃ³dulo utiliza representaÃ§Ãµes vetoriais e simbÃ³licas para lidar com tarefas que envolvem medidas, contagens e proporÃ§Ãµes, sendo essencial para cenÃ¡rios de raciocÃ­nio lÃ³gico ou anÃ¡lise de dados estruturados.

- **Statistic Reasoning:**  
  Executa **inferÃªncias probabilÃ­sticas e correlaÃ§Ãµes estatÃ­sticas**, integrando o aprendizado neural com abordagens bayesianas e modelagem de incerteza.  
  Ã‰ responsÃ¡vel por interpretar dados amostrais, calcular **tendÃªncias e confiabilidade**, e apoiar o sistema em tarefas que exigem **anÃ¡lise quantitativa e inferÃªncia preditiva**.

- **Query Reasoning:**  
  Atua na **interpretaÃ§Ã£o e execuÃ§Ã£o de consultas em linguagem natural**, transformando perguntas textuais em **operaÃ§Ãµes simbÃ³licas e semÃ¢nticas** sobre bancos de conhecimento estruturados (como XML, ontologias e bases vetoriais).  
  Ã‰ o principal componente de **raciocÃ­nio semÃ¢ntico** do rAVA, capaz de decompor perguntas complexas e coordenar respostas explicÃ¡veis.

- **Look-up Module:**  
  Realiza **recuperaÃ§Ã£o direta de conhecimento** a partir de fontes internas (ontologias, vetores de embeddings, documentos RAG) e externas (APIs, bancos de dados, repositÃ³rios XML).  
  Esse mÃ³dulo garante **eficiÃªncia e precisÃ£o** na busca de informaÃ§Ãµes, permitindo ao rAVA fundamentar suas respostas em evidÃªncias e contextos reais.

Esses mÃ³dulos trabalham de forma **complementar e coordenada**, compondo um ecossistema cognitivo que combina **raciocÃ­nio lÃ³gico, inferÃªncia estatÃ­stica e recuperaÃ§Ã£o contextual de conhecimento**.  
O ambiente foi configurado com **Miniconda**, garantindo **isolamento, portabilidade e reprodutibilidade** de todos os experimentos.

---

## Requisitos do Sistema
- **Sistema operacional:** Ubuntu 22.04 LTS ou superior  
- **Python:** 3.10 ou posterior  
- **Gerenciador de ambiente:** Miniconda  
- **Bibliotecas principais:**  
  - `transformers`  
  - `langchain`  
  - `sentence-transformers`  
  - `faiss-cpu`  
  - `torch`  
  - `peft`  
  - `openai`  
  - `fastapi`  
  - `xmltodict`  
  - `lxml`  

- **Hardware recomendado:**  
  - CPU com suporte a AVX  
  - GPU NVIDIA A100 (para aceleraÃ§Ã£o de modelos neurais)  
  - MemÃ³ria RAM mÃ­nima: 16 GB  

---

## InstruÃ§Ãµes para Replicar

1. **Clone este repositÃ³rio:**
   ```bash
   git clone https://github.com/AertySantos/rAVA.git
   cd arquitetura_rava
   ```

2. **Crie um ambiente com o Miniconda e ative-o:**
   ```bash
   conda create -n rava python=3.10 -y
   conda activate rava
   ```

3. **Instale as dependÃªncias:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Execute o mÃ³dulo principal:**
   ```bash
   python3 main.py
   ```
---

## Crie um ambiente com o Miniconda e ative-o

Para garantir a reprodutibilidade e o isolamento do ambiente do **rAVA**, recomenda-se o uso do **Miniconda** como gerenciador de pacotes e ambientes virtuais.

### 1. Verifique se o Miniconda estÃ¡ instalado
```bash
conda --version
```

Se o comando nÃ£o retornar uma versÃ£o, instale o Miniconda a partir do site oficial:  
ðŸ”— [https://docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html)

---

### 2. Crie um novo ambiente para o rAVA
```bash
conda create -n rava python=3.10 -y
```

---

### 3. Ative o ambiente
```bash
conda activate rava
```

---

### 4. Instale as dependÃªncias do projeto
```bash
pip install -r requirements.txt
```

---

### 5. Verifique a instalaÃ§Ã£o
```bash
python3 -m pip list
```

---

### 6. Desative o ambiente (opcional)
```bash
conda deactivate
```

---

## Testes Iniciais

Foram realizados testes com entradas em **voz (T1)**, **imagem (T2)** e **texto (T3)**.  
Os resultados mÃ©dios obtidos estÃ£o resumidos abaixo:

| Tipo de Entrada | Tempo MÃ©dio (s) | Taxa de PrecisÃ£o (%) | Falhas (%) |
| :--------------: | :--------------: | :------------------: | :---------: |
| Voz (T1)         | 79.54            | 55.56                | 14.29       |
| Imagem (T2)      | 78.57            | 84.38                | 12.50       |
| Texto (T3)       | 11.11            | 90.88                | 7.14        |

Esses resultados demonstram que o **mÃ³dulo textual** apresenta maior precisÃ£o, enquanto os mÃ³dulos de voz e imagem oferecem grande potencial de expansÃ£o em contextos multimodais.

---

## Resultados e DiscussÃ£o

Os experimentos mostraram que o rAVA:
- Executa consultas complexas em **linguagem natural**;  
- Realiza **inferÃªncia simbÃ³lica e estatÃ­stica** sobre descritores estruturados;  
- Integra mÃºltiplas modalidades perceptivas (voz, imagem e texto);  
- Oferece **explicabilidade** com rastreabilidade semÃ¢ntica e numÃ©rica.  

O sistema representa um avanÃ§o em **inteligÃªncia cognitiva hÃ­brida**, capaz de unir o raciocÃ­nio simbÃ³lico, o aprendizado neural e a inferÃªncia estatÃ­stica sob uma mesma arquitetura.

---

## Casos de Uso

### 1. AnÃ¡lise de DecisÃµes Judiciais e TransparÃªncia
No domÃ­nio jurÃ­dico, o rAVA Ã© aplicado Ã  **extraÃ§Ã£o e interpretaÃ§Ã£o de metadados de decisÃµes judiciais**, combinando leitura neural de sentenÃ§as com **raciocÃ­nio simbÃ³lico e estatÃ­stico**.  
A arquitetura permite **explicaÃ§Ãµes interpretÃ¡veis** e identificaÃ§Ã£o de **padrÃµes, vieses e recorrÃªncias linguÃ­sticas**, auxiliando pesquisadores e magistrados na tomada de decisÃµes fundamentadas.

---

## ConclusÃ£o
O rAVA consolida-se como uma **arquitetura neuro-simbÃ³lica multimodal**, que combina **razÃ£o simbÃ³lica, inferÃªncia estatÃ­stica e recuperaÃ§Ã£o contextual** sob um mesmo nÃºcleo cognitivo.  
Sua estrutura modular e transparente o posiciona como um exemplo de **IA explicÃ¡vel e responsÃ¡vel**, capaz de operar de forma multimodal e autoexplicativa em diferentes domÃ­nios.  

A convergÃªncia entre **Arithmetic Reasoning, Statistic Reasoning, Query Reasoning e Look-up** reafirma o rAVA como uma proposta sÃ³lida de **inteligÃªncia artificial cognitiva hÃ­brida**, unindo percepÃ§Ã£o, lÃ³gica e explicaÃ§Ã£o.

---

## VÃ­deos
- [DemonstraÃ§Ã£o do rAVA Multimodal](https://youtu.be/XXXXXXXX)


---

## ReferÃªncias -->
 
- [LangChain Documentation](https://python.langchain.com)  
- [Transformers Library â€” Hugging Face](https://huggingface.co/docs/transformers/index)  
- [Retrieval-Augmented Generation (RAG)](https://arxiv.org/pdf/2005.11401.pdf)  
- [Neuro-Symbolic AI: The Third Wave](https://arxiv.org/pdf/2103.13033.pdf)  
```

